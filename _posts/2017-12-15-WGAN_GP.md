---
layout: post
title: "WGAN-GP"
date: 2017-12-15 12:37:14 -0700
comments: true
---

Although the results of WGAN where decent, some geometry of the sheep head was not fully learned. Eyes where missing in some cases, and the total geometry was to blurry. examining the loss function, It seems that the Discriminator approximate the data poorly. As I investigated on the recent results on the field, I stumbled upon an article named <a href = "https://arxiv.org/pdf/1704.00028.pdf" >Improved Training of Wasserstein GANs</a>.
As I mentioned in previous post, the Discriminator function needs to be 1-Lipschitz. In normal WGAN We use <i>weight clipping</i> to enforce that. WGAN-GP uses a <i>gradient penalty</i> instead.

Optimization with <i>WGAN-GP</i> seemed at first almost 2 times slower then normal WGAN, and I noticed that the Discriminator's loss exploded fast. As it turns up this is a common problem with GAN. The Discriminator learn too fast, and the Generator couldn't learn anything valuable. fortunately, this is a quick fix. In each epoch the Discriminator was trained on 5 mini-batches, while the Generator was trained only once. Changing the ratio to $$\frac{5}{3}$$ was fruitful.
[picture is removed due to copyright claims].   

 
WGAN-GP converged faster, with more details captured. It captured more of the geometry, while not overfitting. One could even stop some finer detail, such as the "flower crown" on some of the paintings.

<b>So what is next?</b>

As I examine the results, As a human I could to still differentiate the generator's work from the real paintings. In real paintings the coloring is done more smoothly, while the generator coloring is not as refined.
I thought that it might be fruitful to make several smaller GAN, each with the following purpose:
* learn geometry and lines in paintings.
* learn about identifying smaller objects within painting, and then recreate them
* learn how to color each object.
* learn to assemble multiple objects inside
* scaling the image using <a href= "https://arxiv.org/pdf/1609.04802.pdf" >another GAN method</a>

Recall that neuron networks are designed to mimic (to some extent) the human mind. Maybe one should design art-creating GANs, by mimicking how an art student learns to draw.
To test my thoughts, I first took my raw data and pasted it through an edge detection algorithm. I was hoping that it could recreate some geometry. unfortunately, it did not converge to something meaningful.
I will continue to work on the idea above.

For now, I'm currently building a new dataset of horse painting. using this data set will not be considered copyright infringement as they are composed of hundreds of different painters, and the final product could not derivative work.   